{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from resnets_utils import *\n",
    "from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity\n",
    "from tensorflow.python.framework.ops import EagerTensor\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from test_utils import summary, comparator\n",
    "import public_tests\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0017b68317ffa974",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, training=True, initializer=random_uniform):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    training -- True: Behave in training mode\n",
    "                False: Behave in inference mode\n",
    "    initializer -- to set up the initial weights of a layer. Equals to random uniform initializer\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (m, n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    F1, F2, F3 = filters\n",
    "     \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Second component of main path \n",
    "    X = Conv2D(filters = F2, kernel_size = f, strides = (1,1), padding = 'same', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path \n",
    "    X = Conv2D(filters = F3, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training) # Default axis \n",
    "    \n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e73a8466b807e261",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mWith training=False\u001b[0m\n",
      "\n",
      "[[[  0.        0.        0.        0.     ]\n",
      "  [  0.        0.        0.        0.     ]]\n",
      "\n",
      " [[192.71234 192.71234 192.71234  96.85617]\n",
      "  [ 96.85617  96.85617  96.85617  48.92808]]\n",
      "\n",
      " [[578.1371  578.1371  578.1371  290.5685 ]\n",
      "  [290.5685  290.5685  290.5685  146.78426]]]\n",
      "96.85617\n",
      "\n",
      "\u001b[1mWith training=True\u001b[0m\n",
      "\n",
      "[[[0.      0.      0.      0.     ]\n",
      "  [0.      0.      0.      0.     ]]\n",
      "\n",
      " [[0.40739 0.40739 0.40739 0.40739]\n",
      "  [0.40739 0.40739 0.40739 0.40739]]\n",
      "\n",
      " [[4.99991 4.99991 4.99991 3.25948]\n",
      "  [3.25948 3.25948 3.25948 2.40739]]]\n",
      "\u001b[32mAll tests passed!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "X1 = np.ones((1, 4, 4, 3)) * -1\n",
    "X2 = np.ones((1, 4, 4, 3)) * 1\n",
    "X3 = np.ones((1, 4, 4, 3)) * 3\n",
    "\n",
    "X = np.concatenate((X1, X2, X3), axis = 0).astype(np.float32)\n",
    "\n",
    "A3 = identity_block(X, f=2, filters=[4, 4, 3],\n",
    "                   initializer=lambda seed=0:constant(value=1),\n",
    "                   training=False)\n",
    "print('\\033[1mWith training=False\\033[0m\\n')\n",
    "A3np = A3.numpy()\n",
    "print(np.around(A3.numpy()[:,(0,-1),:,:].mean(axis = 3), 5))\n",
    "resume = A3np[:,(0,-1),:,:].mean(axis = 3)\n",
    "print(resume[1, 1, 0])\n",
    "\n",
    "print('\\n\\033[1mWith training=True\\033[0m\\n')\n",
    "np.random.seed(1)\n",
    "A4 = identity_block(X, f=2, filters=[3, 3, 3],\n",
    "                   initializer=lambda seed=0:constant(value=1),\n",
    "                   training=True)\n",
    "print(np.around(A4.numpy()[:,(0,-1),:,:].mean(axis = 3), 5))\n",
    "\n",
    "public_tests.identity_block_test(identity_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-df47af4847e5335f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, s = 2, training=True, initializer=glorot_uniform):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    s -- Integer, specifying the stride to be used\n",
    "    training -- True: Behave in training mode\n",
    "                False: Behave in inference mode\n",
    "    initializer -- to set up the initial weights of a layer. Equals to Glorot uniform initializer, \n",
    "                   also called Xavier uniform initializer.\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    X_shortcut = X\n",
    "\n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters = F2, kernel_size = f, strides = (1, 1), padding='same', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters = F3, kernel_size = 1, strides = (1, 1), padding='valid', kernel_initializer = initializer(seed=0))(X) \n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    \n",
    "    X_shortcut = Conv2D(filters = F3, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X_shortcut) \n",
    "    X_shortcut = BatchNormalization(axis = 3)(X_shortcut, training=training)\n",
    "\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-95c291eb244218fe",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.         0.66683817 0.         0.         0.88853896 0.5274254 ]\n",
      "  [0.         0.65053666 0.         0.         0.89592844 0.49965227]]\n",
      "\n",
      " [[0.         0.6312079  0.         0.         0.8636247  0.47643146]\n",
      "  [0.         0.5688321  0.         0.         0.85534114 0.41709304]]], shape=(2, 2, 6), dtype=float32)\n",
      "\u001b[92mAll tests passed!\n"
     ]
    }
   ],
   "source": [
    "from outputs import convolutional_block_output1, convolutional_block_output2\n",
    "np.random.seed(1)\n",
    "#X = np.random.randn(3, 4, 4, 6).astype(np.float32)\n",
    "X1 = np.ones((1, 4, 4, 3)) * -1\n",
    "X2 = np.ones((1, 4, 4, 3)) * 1\n",
    "X3 = np.ones((1, 4, 4, 3)) * 3\n",
    "\n",
    "X = np.concatenate((X1, X2, X3), axis = 0).astype(np.float32)\n",
    "\n",
    "A = convolutional_block(X, f = 2, filters = [2, 4, 6], training=False)\n",
    "\n",
    "assert type(A) == EagerTensor, \"Use only tensorflow and keras functions\"\n",
    "assert tuple(tf.shape(A).numpy()) == (3, 2, 2, 6), \"Wrong shape.\"\n",
    "assert np.allclose(A.numpy(), convolutional_block_output1), \"Wrong values when training=False.\"\n",
    "print(A[0])\n",
    "\n",
    "B = convolutional_block(X, f = 2, filters = [2, 4, 6], training=True)\n",
    "assert np.allclose(B.numpy(), convolutional_block_output2), \"Wrong values when training=True.\"\n",
    "\n",
    "print('\\033[92mAll tests passed!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-10dc95a4cf6275b9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ResNet50(input_shape = (64, 64, 3), classes = 6):\n",
    "    \"\"\"\n",
    "    Stage-wise implementation of the architecture of the popular ResNet50:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> FLATTEN -> DENSE \n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    \n",
    "    ## Stage 3\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], s = 2)\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512]) \n",
    "    \n",
    "    ## Stage 4\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], s = 2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024]) \n",
    "    X = identity_block(X, 3, [256, 256, 1024]) \n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024]) \n",
    "    X = identity_block(X, 3, [256, 256, 1024]) \n",
    "\n",
    "    ## Stage 5\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512,2048], s = 2)\n",
    "    X = identity_block(X, 3, [512, 512,2048])  \n",
    "    X = identity_block(X, 3, [512, 512,2048])\n",
    "\n",
    "    X =  AveragePooling2D((2,2))(X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 70, 70, 3)    0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_356 (Conv2D)             (None, 32, 32, 64)   9472        zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_356 (BatchN (None, 32, 32, 64)   256         conv2d_356[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_322 (Activation)     (None, 32, 32, 64)   0           batch_normalization_356[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 15, 15, 64)   0           activation_322[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_357 (Conv2D)             (None, 15, 15, 64)   4160        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_357 (BatchN (None, 15, 15, 64)   256         conv2d_357[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_323 (Activation)     (None, 15, 15, 64)   0           batch_normalization_357[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_358 (Conv2D)             (None, 15, 15, 64)   36928       activation_323[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_358 (BatchN (None, 15, 15, 64)   256         conv2d_358[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_324 (Activation)     (None, 15, 15, 64)   0           batch_normalization_358[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_359 (Conv2D)             (None, 15, 15, 256)  16640       activation_324[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_360 (Conv2D)             (None, 15, 15, 256)  16640       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_359 (BatchN (None, 15, 15, 256)  1024        conv2d_359[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_360 (BatchN (None, 15, 15, 256)  1024        conv2d_360[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_107 (Add)                   (None, 15, 15, 256)  0           batch_normalization_359[0][0]    \n",
      "                                                                 batch_normalization_360[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_325 (Activation)     (None, 15, 15, 256)  0           add_107[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_361 (Conv2D)             (None, 15, 15, 64)   16448       activation_325[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_361 (BatchN (None, 15, 15, 64)   256         conv2d_361[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_326 (Activation)     (None, 15, 15, 64)   0           batch_normalization_361[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_362 (Conv2D)             (None, 15, 15, 64)   36928       activation_326[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_362 (BatchN (None, 15, 15, 64)   256         conv2d_362[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_327 (Activation)     (None, 15, 15, 64)   0           batch_normalization_362[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_363 (Conv2D)             (None, 15, 15, 256)  16640       activation_327[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_363 (BatchN (None, 15, 15, 256)  1024        conv2d_363[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_108 (Add)                   (None, 15, 15, 256)  0           batch_normalization_363[0][0]    \n",
      "                                                                 activation_325[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_328 (Activation)     (None, 15, 15, 256)  0           add_108[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_364 (Conv2D)             (None, 15, 15, 64)   16448       activation_328[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_364 (BatchN (None, 15, 15, 64)   256         conv2d_364[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_329 (Activation)     (None, 15, 15, 64)   0           batch_normalization_364[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_365 (Conv2D)             (None, 15, 15, 64)   36928       activation_329[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_365 (BatchN (None, 15, 15, 64)   256         conv2d_365[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_330 (Activation)     (None, 15, 15, 64)   0           batch_normalization_365[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_366 (Conv2D)             (None, 15, 15, 256)  16640       activation_330[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_366 (BatchN (None, 15, 15, 256)  1024        conv2d_366[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_109 (Add)                   (None, 15, 15, 256)  0           batch_normalization_366[0][0]    \n",
      "                                                                 activation_328[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_331 (Activation)     (None, 15, 15, 256)  0           add_109[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_367 (Conv2D)             (None, 8, 8, 128)    32896       activation_331[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_367 (BatchN (None, 8, 8, 128)    512         conv2d_367[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_332 (Activation)     (None, 8, 8, 128)    0           batch_normalization_367[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_368 (Conv2D)             (None, 8, 8, 128)    147584      activation_332[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_368 (BatchN (None, 8, 8, 128)    512         conv2d_368[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_333 (Activation)     (None, 8, 8, 128)    0           batch_normalization_368[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_369 (Conv2D)             (None, 8, 8, 512)    66048       activation_333[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_370 (Conv2D)             (None, 8, 8, 512)    131584      activation_331[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_369 (BatchN (None, 8, 8, 512)    2048        conv2d_369[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_370 (BatchN (None, 8, 8, 512)    2048        conv2d_370[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_110 (Add)                   (None, 8, 8, 512)    0           batch_normalization_369[0][0]    \n",
      "                                                                 batch_normalization_370[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_334 (Activation)     (None, 8, 8, 512)    0           add_110[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_371 (Conv2D)             (None, 8, 8, 128)    65664       activation_334[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_371 (BatchN (None, 8, 8, 128)    512         conv2d_371[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_335 (Activation)     (None, 8, 8, 128)    0           batch_normalization_371[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_372 (Conv2D)             (None, 8, 8, 128)    147584      activation_335[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_372 (BatchN (None, 8, 8, 128)    512         conv2d_372[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_336 (Activation)     (None, 8, 8, 128)    0           batch_normalization_372[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_373 (Conv2D)             (None, 8, 8, 512)    66048       activation_336[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_373 (BatchN (None, 8, 8, 512)    2048        conv2d_373[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_111 (Add)                   (None, 8, 8, 512)    0           batch_normalization_373[0][0]    \n",
      "                                                                 activation_334[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_337 (Activation)     (None, 8, 8, 512)    0           add_111[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_374 (Conv2D)             (None, 8, 8, 128)    65664       activation_337[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_374 (BatchN (None, 8, 8, 128)    512         conv2d_374[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_338 (Activation)     (None, 8, 8, 128)    0           batch_normalization_374[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_375 (Conv2D)             (None, 8, 8, 128)    147584      activation_338[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_375 (BatchN (None, 8, 8, 128)    512         conv2d_375[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_339 (Activation)     (None, 8, 8, 128)    0           batch_normalization_375[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_376 (Conv2D)             (None, 8, 8, 512)    66048       activation_339[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_376 (BatchN (None, 8, 8, 512)    2048        conv2d_376[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_112 (Add)                   (None, 8, 8, 512)    0           batch_normalization_376[0][0]    \n",
      "                                                                 activation_337[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_340 (Activation)     (None, 8, 8, 512)    0           add_112[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_377 (Conv2D)             (None, 8, 8, 128)    65664       activation_340[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_377 (BatchN (None, 8, 8, 128)    512         conv2d_377[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_341 (Activation)     (None, 8, 8, 128)    0           batch_normalization_377[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_378 (Conv2D)             (None, 8, 8, 128)    147584      activation_341[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_378 (BatchN (None, 8, 8, 128)    512         conv2d_378[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_342 (Activation)     (None, 8, 8, 128)    0           batch_normalization_378[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_379 (Conv2D)             (None, 8, 8, 512)    66048       activation_342[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_379 (BatchN (None, 8, 8, 512)    2048        conv2d_379[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_113 (Add)                   (None, 8, 8, 512)    0           batch_normalization_379[0][0]    \n",
      "                                                                 activation_340[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_343 (Activation)     (None, 8, 8, 512)    0           add_113[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_380 (Conv2D)             (None, 4, 4, 256)    131328      activation_343[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_380 (BatchN (None, 4, 4, 256)    1024        conv2d_380[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_344 (Activation)     (None, 4, 4, 256)    0           batch_normalization_380[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_381 (Conv2D)             (None, 4, 4, 256)    590080      activation_344[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_381 (BatchN (None, 4, 4, 256)    1024        conv2d_381[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_345 (Activation)     (None, 4, 4, 256)    0           batch_normalization_381[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_382 (Conv2D)             (None, 4, 4, 1024)   263168      activation_345[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_383 (Conv2D)             (None, 4, 4, 1024)   525312      activation_343[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_382 (BatchN (None, 4, 4, 1024)   4096        conv2d_382[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_383 (BatchN (None, 4, 4, 1024)   4096        conv2d_383[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_114 (Add)                   (None, 4, 4, 1024)   0           batch_normalization_382[0][0]    \n",
      "                                                                 batch_normalization_383[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_346 (Activation)     (None, 4, 4, 1024)   0           add_114[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_384 (Conv2D)             (None, 4, 4, 256)    262400      activation_346[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_384 (BatchN (None, 4, 4, 256)    1024        conv2d_384[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_347 (Activation)     (None, 4, 4, 256)    0           batch_normalization_384[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_385 (Conv2D)             (None, 4, 4, 256)    590080      activation_347[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_385 (BatchN (None, 4, 4, 256)    1024        conv2d_385[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_348 (Activation)     (None, 4, 4, 256)    0           batch_normalization_385[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_386 (Conv2D)             (None, 4, 4, 1024)   263168      activation_348[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_386 (BatchN (None, 4, 4, 1024)   4096        conv2d_386[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_115 (Add)                   (None, 4, 4, 1024)   0           batch_normalization_386[0][0]    \n",
      "                                                                 activation_346[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_349 (Activation)     (None, 4, 4, 1024)   0           add_115[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_387 (Conv2D)             (None, 4, 4, 256)    262400      activation_349[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_387 (BatchN (None, 4, 4, 256)    1024        conv2d_387[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_350 (Activation)     (None, 4, 4, 256)    0           batch_normalization_387[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_388 (Conv2D)             (None, 4, 4, 256)    590080      activation_350[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_388 (BatchN (None, 4, 4, 256)    1024        conv2d_388[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_351 (Activation)     (None, 4, 4, 256)    0           batch_normalization_388[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_389 (Conv2D)             (None, 4, 4, 1024)   263168      activation_351[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_389 (BatchN (None, 4, 4, 1024)   4096        conv2d_389[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_116 (Add)                   (None, 4, 4, 1024)   0           batch_normalization_389[0][0]    \n",
      "                                                                 activation_349[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_352 (Activation)     (None, 4, 4, 1024)   0           add_116[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_390 (Conv2D)             (None, 4, 4, 256)    262400      activation_352[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_390 (BatchN (None, 4, 4, 256)    1024        conv2d_390[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_353 (Activation)     (None, 4, 4, 256)    0           batch_normalization_390[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_391 (Conv2D)             (None, 4, 4, 256)    590080      activation_353[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_391 (BatchN (None, 4, 4, 256)    1024        conv2d_391[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_354 (Activation)     (None, 4, 4, 256)    0           batch_normalization_391[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_392 (Conv2D)             (None, 4, 4, 1024)   263168      activation_354[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_392 (BatchN (None, 4, 4, 1024)   4096        conv2d_392[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_117 (Add)                   (None, 4, 4, 1024)   0           batch_normalization_392[0][0]    \n",
      "                                                                 activation_352[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_355 (Activation)     (None, 4, 4, 1024)   0           add_117[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_393 (Conv2D)             (None, 4, 4, 256)    262400      activation_355[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_393 (BatchN (None, 4, 4, 256)    1024        conv2d_393[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_356 (Activation)     (None, 4, 4, 256)    0           batch_normalization_393[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_394 (Conv2D)             (None, 4, 4, 256)    590080      activation_356[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_394 (BatchN (None, 4, 4, 256)    1024        conv2d_394[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_357 (Activation)     (None, 4, 4, 256)    0           batch_normalization_394[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_395 (Conv2D)             (None, 4, 4, 1024)   263168      activation_357[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_395 (BatchN (None, 4, 4, 1024)   4096        conv2d_395[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_118 (Add)                   (None, 4, 4, 1024)   0           batch_normalization_395[0][0]    \n",
      "                                                                 activation_355[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_358 (Activation)     (None, 4, 4, 1024)   0           add_118[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_396 (Conv2D)             (None, 4, 4, 256)    262400      activation_358[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_396 (BatchN (None, 4, 4, 256)    1024        conv2d_396[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_359 (Activation)     (None, 4, 4, 256)    0           batch_normalization_396[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_397 (Conv2D)             (None, 4, 4, 256)    590080      activation_359[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_397 (BatchN (None, 4, 4, 256)    1024        conv2d_397[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_360 (Activation)     (None, 4, 4, 256)    0           batch_normalization_397[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_398 (Conv2D)             (None, 4, 4, 1024)   263168      activation_360[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_398 (BatchN (None, 4, 4, 1024)   4096        conv2d_398[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_119 (Add)                   (None, 4, 4, 1024)   0           batch_normalization_398[0][0]    \n",
      "                                                                 activation_358[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_361 (Activation)     (None, 4, 4, 1024)   0           add_119[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_399 (Conv2D)             (None, 2, 2, 512)    524800      activation_361[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_399 (BatchN (None, 2, 2, 512)    2048        conv2d_399[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_362 (Activation)     (None, 2, 2, 512)    0           batch_normalization_399[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_400 (Conv2D)             (None, 2, 2, 512)    2359808     activation_362[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_400 (BatchN (None, 2, 2, 512)    2048        conv2d_400[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_363 (Activation)     (None, 2, 2, 512)    0           batch_normalization_400[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_401 (Conv2D)             (None, 2, 2, 2048)   1050624     activation_363[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_402 (Conv2D)             (None, 2, 2, 2048)   2099200     activation_361[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_401 (BatchN (None, 2, 2, 2048)   8192        conv2d_401[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_402 (BatchN (None, 2, 2, 2048)   8192        conv2d_402[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_120 (Add)                   (None, 2, 2, 2048)   0           batch_normalization_401[0][0]    \n",
      "                                                                 batch_normalization_402[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_364 (Activation)     (None, 2, 2, 2048)   0           add_120[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_403 (Conv2D)             (None, 2, 2, 512)    1049088     activation_364[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_403 (BatchN (None, 2, 2, 512)    2048        conv2d_403[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_365 (Activation)     (None, 2, 2, 512)    0           batch_normalization_403[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_404 (Conv2D)             (None, 2, 2, 512)    2359808     activation_365[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_404 (BatchN (None, 2, 2, 512)    2048        conv2d_404[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_366 (Activation)     (None, 2, 2, 512)    0           batch_normalization_404[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_405 (Conv2D)             (None, 2, 2, 2048)   1050624     activation_366[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_405 (BatchN (None, 2, 2, 2048)   8192        conv2d_405[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_121 (Add)                   (None, 2, 2, 2048)   0           batch_normalization_405[0][0]    \n",
      "                                                                 activation_364[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_367 (Activation)     (None, 2, 2, 2048)   0           add_121[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_406 (Conv2D)             (None, 2, 2, 512)    1049088     activation_367[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_406 (BatchN (None, 2, 2, 512)    2048        conv2d_406[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_368 (Activation)     (None, 2, 2, 512)    0           batch_normalization_406[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_407 (Conv2D)             (None, 2, 2, 512)    2359808     activation_368[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_407 (BatchN (None, 2, 2, 512)    2048        conv2d_407[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_369 (Activation)     (None, 2, 2, 512)    0           batch_normalization_407[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_408 (Conv2D)             (None, 2, 2, 2048)   1050624     activation_369[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_408 (BatchN (None, 2, 2, 2048)   8192        conv2d_408[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_122 (Add)                   (None, 2, 2, 2048)   0           batch_normalization_408[0][0]    \n",
      "                                                                 activation_367[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_370 (Activation)     (None, 2, 2, 2048)   0           add_122[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 1, 1, 2048)   0           activation_370[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 2048)         0           average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 6)            12294       flatten_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 23,600,006\n",
      "Trainable params: 23,546,886\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(input_shape = (64, 64, 3), classes = 6)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-866b891ec47ccb7b",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mAll tests passed!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from outputs import ResNet50_summary\n",
    "\n",
    "model = ResNet50(input_shape = (64, 64, 3), classes = 6)\n",
    "\n",
    "comparator(summary(model), ResNet50_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the Keras Tutorial Notebook, prior to training a model, you need to configure the learning process by compiling the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1080\n",
      "number of test examples = 120\n",
      "X_train shape: (1080, 64, 64, 3)\n",
      "Y_train shape: (1080, 6)\n",
      "X_test shape: (120, 64, 64, 3)\n",
      "Y_test shape: (120, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
    "\n",
    "# Normalize image vectors\n",
    "X_train = X_train_orig / 255.\n",
    "X_test = X_test_orig / 255.\n",
    "\n",
    "# Convert training and test labels to one hot matrices\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "34/34 [==============================] - 2s 54ms/step - loss: 1.7668 - accuracy: 0.4815\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 1s 43ms/step - loss: 0.5305 - accuracy: 0.8083\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.2639 - accuracy: 0.9093\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 0.3443 - accuracy: 0.8954\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.9953 - accuracy: 0.7213\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 1s 25ms/step - loss: 0.9005 - accuracy: 0.6833\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.4098 - accuracy: 0.8657\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.5007 - accuracy: 0.8454\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.3631 - accuracy: 0.8806\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.1796 - accuracy: 0.9389\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f004c266630>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs = 10, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2874 - accuracy: 0.9083\n",
      "Loss = 0.2874080538749695\n",
      "Test Accuracy = 0.9083333611488342\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
